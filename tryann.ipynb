{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc35a19-b38f-4951-bc22-7684515573bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bigger ANN model 4 Hidden layers amd 1 output layer\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from glob import glob\n",
    "\n",
    "# Constants for tire degradation\n",
    "SOFT_DEG = 0.01\n",
    "MEDIUM_DEG = 0.007\n",
    "HARD_DEG = 0.005\n",
    "NUM_LAPS = 58  # Number of laps for prediction\n",
    "BATCH_SIZE = 5000  # Number of samples per training batch\n",
    "\n",
    "# Path to stored CSV data (Update this path to your dataset location)\n",
    "DATA_FOLDER = \"E:/fastf1_csv_data/Data/Abu Dhabi Grand Prix/Race\"\n",
    "\n",
    "def load_offline_data():\n",
    "    \"\"\"Loads lap data from stored CSV files.\"\"\"\n",
    "    all_files = glob(os.path.join(DATA_FOLDER, \"*.csv\"))  # Get all CSV files\n",
    "    df_list = []  # Store each CSV's data\n",
    "\n",
    "    for file in all_files:\n",
    "        df = pd.read_csv(file)\n",
    "        df_list.append(df)\n",
    "\n",
    "    return pd.concat(df_list, ignore_index=True)  # Merge all CSVs into one DataFrame\n",
    "\n",
    "def prepare_training_data(df):\n",
    "    \"\"\"Processes offline lap data into training features and targets.\"\"\"\n",
    "    df = df.dropna(subset=['LapTime', 'Compound'])  # Remove missing lap times\n",
    "    df['LapTime'] = pd.to_timedelta(df['LapTime']).dt.total_seconds()  # Convert to seconds\n",
    "\n",
    "    soft_data = df[df['Compound'] == 'SOFT']\n",
    "    medium_data = df[df['Compound'] == 'MEDIUM']\n",
    "    hard_data = df[df['Compound'] == 'HARD']\n",
    "\n",
    "    def process_compound_data(compound_data):\n",
    "        lap_times = compound_data['LapTime'].values\n",
    "        laps = np.arange(len(lap_times)).reshape(-1, 1)  # Use lap numbers as a feature\n",
    "        return laps, lap_times  # X (features), y (targets)\n",
    "\n",
    "    # Process each compound\n",
    "    soft_X, soft_y = process_compound_data(soft_data)\n",
    "    medium_X, medium_y = process_compound_data(medium_data)\n",
    "    hard_X, hard_y = process_compound_data(hard_data)\n",
    "\n",
    "    return (soft_X, soft_y), (medium_X, medium_y), (hard_X, hard_y)\n",
    "\n",
    "def build_model():\n",
    "    \"\"\"Builds and compiles the ANN model.\"\"\"\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(512, activation=LeakyReLU(alpha=0.1), input_shape=(1,)), # Lap number + Degradation\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(128,activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(32, activation=LeakyReLU(alpha=0.1)),\n",
    "        tf.keras.layers.Dense(1)  # Output: Lap Time\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='mse',\n",
    "                  metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# Load offline data\n",
    "df = load_offline_data()\n",
    "\n",
    "# Prepare data in batches\n",
    "(soft_X, soft_y), (medium_X, medium_y), (hard_X, hard_y) = prepare_training_data(df)\n",
    "\n",
    "# Train in batches\n",
    "soft_model = build_model()\n",
    "medium_model = build_model()\n",
    "hard_model = build_model()\n",
    "\n",
    "def train_model_in_batches(model, X, y, batch_size):\n",
    "    \"\"\"Trains the model using batch processing to optimize memory usage.\"\"\"\n",
    "    num_samples = len(X)\n",
    "    for start in range(0, num_samples, batch_size):\n",
    "        end = min(start + batch_size, num_samples)\n",
    "        model.fit(X[start:end], y[start:end], epochs=300, verbose=1)  # Train on batch\n",
    "\n",
    "# Train models in batches\n",
    "print(\"\\nTraining Soft Tire Model...\")\n",
    "train_model_in_batches(soft_model, soft_X, soft_y, BATCH_SIZE)\n",
    "\n",
    "print(\"\\nTraining Medium Tire Model...\")\n",
    "train_model_in_batches(medium_model, medium_X, medium_y, BATCH_SIZE)\n",
    "\n",
    "print(\"\\nTraining Hard Tire Model...\")\n",
    "train_model_in_batches(hard_model, hard_X, hard_y, BATCH_SIZE)\n",
    "\n",
    "# Predict lap times\n",
    "def predict_lap_times(tire_type, initial_lap):\n",
    "    \"\"\"Predicts lap times for a given tire type over multiple laps.\"\"\"\n",
    "    if tire_type == \"soft\":\n",
    "        model, degradation = soft_model, SOFT_DEG\n",
    "    elif tire_type == \"medium\":\n",
    "        model, degradation = medium_model, MEDIUM_DEG\n",
    "    elif tire_type == \"hard\":\n",
    "        model, degradation = hard_model, HARD_DEG\n",
    "    else:\n",
    "        raise ValueError(\"Invalid tire type. Choose from 'soft', 'medium', or 'hard'.\")\n",
    "\n",
    "    lap_times = []\n",
    "    lap_number = np.array([[initial_lap]])\n",
    "\n",
    "    for lap in range(NUM_LAPS):\n",
    "        lap_time = model.predict(lap_number, verbose=0)[0][0]\n",
    "        lap_times.append(lap_time)\n",
    "        lap_number[0, 0] += 1  # Increment lap number\n",
    "\n",
    "    return lap_times\n",
    "\n",
    "def seconds_to_min_sec(predicted_lap_times):\n",
    "    return[f\"{int(time // 60)}:{time % 60:.3f}\" for time in predicted_lap_times]\n",
    "\n",
    "# Example prediction\n",
    "initial_lap = 1\n",
    "tire_type = \"hard\"\n",
    "predicted_lap_times = predict_lap_times(tire_type, initial_lap)\n",
    "formatted_lap_times = seconds_to_min_sec(predicted_lap_times)\n",
    "print(\"\\nPredicted Lap Times (MM:SS.mmm):\")\n",
    "for i, lap_time in enumerate(formatted_lap_times, start=1):\n",
    "    print(f\"Lap {i}: {lap_time}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689d4805-0e71-47bc-aaa2-1693e0738fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from glob import glob\n",
    "\n",
    "# Constants\n",
    "BATCH_SIZE = 10000\n",
    "NUM_LAPS = 58\n",
    "DATA_FOLDER = \"E:/fastf1_csv_data/Data/Belgian Grand Prix/Race\"\n",
    "\n",
    "# Function to Load Offline CSV Data\n",
    "def load_offline_data():\n",
    "    \"\"\"Loads lap data from stored CSV files.\"\"\"\n",
    "    all_files = glob(os.path.join(DATA_FOLDER, '*.csv'))\n",
    "    df_list = []\n",
    "\n",
    "    for file in all_files:\n",
    "        df = pd.read_csv(file)\n",
    "        df_list.append(df)\n",
    "\n",
    "    return pd.concat(df_list, ignore_index=True) if df_list else pd.DataFrame()  # Merge all CSVs into one DataFrame\n",
    "\n",
    "# Function to Calculate Lap Time Degradation\n",
    "def calculate_degradation(lap_times):\n",
    "    \"\"\"Calculates degradation as the difference between consecutive lap times.\"\"\"\n",
    "    degradation = np.diff(lap_times, prepend=lap_times[0])  # First lap has no degradation\n",
    "    return degradation\n",
    "\n",
    "# Function to Prepare Data\n",
    "def prepare_training_data(df):\n",
    "    \"\"\"Processes offline lap data into training features and targets.\"\"\"\n",
    "    df = df.dropna(subset=['LapTime', 'Compound'])  # Remove missing lap times\n",
    "    df['LapTime'] = pd.to_timedelta(df['LapTime']).dt.total_seconds()  # Convert LapTime to seconds\n",
    "\n",
    "    soft_data = df[df['Compound'] == 'SOFT']\n",
    "    medium_data = df[df['Compound'] == 'MEDIUM']\n",
    "    hard_data = df[df['Compound'] == 'HARD']\n",
    "\n",
    "    def process_compound_data(compound_data):\n",
    "        lap_times = compound_data['LapTime'].values\n",
    "        degradation = calculate_degradation(lap_times)\n",
    "        laps = np.arange(1, len(lap_times) + 1).reshape(-1, 1)  # Lap number as feature\n",
    "        return np.hstack((laps, degradation.reshape(-1, 1))), lap_times\n",
    "\n",
    "    soft_X, soft_y = process_compound_data(soft_data)\n",
    "    medium_X, medium_y = process_compound_data(medium_data)\n",
    "    hard_X, hard_y = process_compound_data(hard_data)\n",
    "\n",
    "    return (soft_X, soft_y), (medium_X, medium_y), (hard_X, hard_y)\n",
    "\n",
    "# Function to Build Model\n",
    "def build_model():\n",
    "    \"\"\"Builds and compiles the ANN model.\"\"\"\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(512, activation=LeakyReLU(alpha=0.1), input_shape=(2,)), # Lap number + Degradation\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(32, activation=LeakyReLU(alpha=0.1)),\n",
    "        tf.keras.layers.Dense(1)  # Output: Lap Time\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='mse',\n",
    "                  metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# Function to Train Model in Batches\n",
    "def train_model_in_batches(model, X, y, batch_size):\n",
    "    \"\"\"Trains the model using batch processing to optimize memory usage.\"\"\"\n",
    "    num_samples = len(X)\n",
    "    for start in range(0, num_samples, batch_size):\n",
    "        end = min(start + batch_size, num_samples)\n",
    "        model.fit(X[start:end], y[start:end], epochs=200, verbose=1, batch_size=32)\n",
    "\n",
    "# Function to Predict Lap Times\n",
    "def predict_lap_times(model, initial_lap, initial_lap_time):\n",
    "    \"\"\"Predicts lap times dynamically using calculated degradation.\"\"\"\n",
    "    lap_times = []\n",
    "    lap_number = initial_lap\n",
    "    last_lap_time = initial_lap_time\n",
    "\n",
    "    for _ in range(NUM_LAPS):\n",
    "        # Create input feature (Lap Number, Last Lap Degradation)\n",
    "        degradation = last_lap_time - lap_times[-1] if lap_times else 0\n",
    "        input_features = np.array([[lap_number, degradation]])\n",
    "\n",
    "        # Predict next lap time\n",
    "        lap_time = model.predict(input_features, verbose=0)[0][0]\n",
    "        lap_times.append(lap_time)\n",
    "\n",
    "        # Update values for next lap\n",
    "        lap_number += 1\n",
    "        last_lap_time = lap_time  # Update last lap time\n",
    "\n",
    "    return lap_times\n",
    "\n",
    "# Convert Seconds to MM:SS.mmm Format\n",
    "def seconds_to_min_sec(predicted_lap_times):\n",
    "    \"\"\"Converts lap times from seconds to MM:SS.mmm format.\"\"\"\n",
    "    return [f\"{int(time // 60)}:{time % 60:.3f}\" for time in predicted_lap_times]\n",
    "\n",
    "# Function to Select Model Based on Tire Type\n",
    "def tire_type_model(tire_type):\n",
    "    if tire_type == \"soft\":\n",
    "        return soft_model\n",
    "    elif tire_type == \"medium\":\n",
    "        return medium_model\n",
    "    elif tire_type == \"hard\":\n",
    "        return hard_model\n",
    "    else:\n",
    "        raise ValueError(\"Invalid tire type\")\n",
    "\n",
    "# Load Offline Data\n",
    "df = load_offline_data()\n",
    "if df.empty:\n",
    "    print(\"⚠ No offline data found! Check your CSV files.\")\n",
    "else:\n",
    "    # Prepare Data\n",
    "    (soft_X, soft_y), (medium_X, medium_y), (hard_X, hard_y) = prepare_training_data(df)\n",
    "\n",
    "    # Build and Train Models\n",
    "    soft_model = build_model()\n",
    "    medium_model = build_model()\n",
    "    hard_model = build_model()\n",
    "\n",
    "    print('\\n Training Soft Model...')\n",
    "    train_model_in_batches(soft_model, soft_X, soft_y, BATCH_SIZE)\n",
    "\n",
    "    print('\\n Training Medium Model...')\n",
    "    train_model_in_batches(medium_model, medium_X, medium_y, BATCH_SIZE)\n",
    "\n",
    "    print('\\n Training Hard Model...')\n",
    "    train_model_in_batches(hard_model, hard_X, hard_y, BATCH_SIZE)\n",
    "\n",
    "    # Predict Lap Times\n",
    "    initial_lap = 1\n",
    "    tire_type = \"hard\"\n",
    "    model = tire_type_model(tire_type)\n",
    "    initial_lap_time = hard_y[0]  # Start with the first lap time\n",
    "\n",
    "    predicted_lap_times = predict_lap_times(model, initial_lap, initial_lap_time)\n",
    "\n",
    "    # Convert to Minutes:Seconds Format\n",
    "    formatted_lap_times = seconds_to_min_sec(predicted_lap_times)\n",
    "\n",
    "    print(\"\\nPredicted Lap Times (MM:SS.mmm):\")\n",
    "    for i, lap_time in enumerate(formatted_lap_times, start=1):\n",
    "        print(f\"Lap {i}: {lap_time}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2798b3-34c6-4309-bef2-40b1a9771976",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = fastf1.get_session(2019, 'Bahrain','Q')\n",
    "session.load(telemetry=True, laps=True, weather=True)\n",
    "lap_data = session.laps\n",
    "print(lap_data.head())\n",
    "lap_data.to_csv('lap_data_table.csv', index = True)\n",
    "print(\"Lap data has been saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4fce57-113c-46b1-8174-fd74b64234eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.get_driver('HAM')\n",
    "session.load(telemetry=True, laps=True, weather=True)\n",
    "session.laps\n",
    "session = fastf1.get_session(2019, 'Bahrain','R')\n",
    "session.load(telemetry=True, laps=True, weather=True)\n",
    "lap_data = session.laps\n",
    "print(lap_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10115e4-565b-4872-ab83-c6ee921afcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LeakyReLU, LSTM\n",
    "from glob import glob\n",
    "\n",
    "# Constants\n",
    "BATCH_SIZE = 5000\n",
    "NUM_LAPS_TO_PREDICT = 58  # Number of laps to predict\n",
    "DATA_FOLDER = \"E:/fastf1_csv_data/Data/Belgian Grand Prix/Race\"\n",
    "\n",
    "# Fuel & Track Temp Inputs\n",
    "INITIAL_FUEL_LOAD = 105  # Full F1 race fuel load (kg)\n",
    "FUEL_BURN_RATE = 1.5  # Estimated fuel loss per lap (kg)\n",
    "INITIAL_TRACK_TEMP = 35  # Track temperature in Celsius\n",
    "TEMP_DECREASE_LAPS = 10  # Decrease track temp by 1°C every 10 laps\n",
    "\n",
    "# **Tire Degradation Parameters**\n",
    "DEGRADATION_FACTORS = {\n",
    "    \"SOFT\": (0.07, 2.0),\n",
    "    \"MEDIUM\": (0.05, 1.5),\n",
    "    \"HARD\": (0.03, 1.2)\n",
    "}\n",
    "\n",
    "# **Load Offline CSV Data**\n",
    "def load_offline_data():\n",
    "    all_files = glob(os.path.join(DATA_FOLDER, '*.csv'))\n",
    "    df_list = [pd.read_csv(file) for file in all_files]\n",
    "    return pd.concat(df_list, ignore_index=True) if df_list else pd.DataFrame()\n",
    "\n",
    "# **Calculate Tire Degradation**\n",
    "def calculate_degradation(lap_numbers, compound):\n",
    "    \"\"\"Degradation is based on different tire compounds.\"\"\"\n",
    "    k1, k2 = DEGRADATION_FACTORS[compound]\n",
    "    return k1 * np.log(k2 * lap_numbers + 1)\n",
    "\n",
    "# **Prepare Training Data (For All Drivers & Compounds)**\n",
    "def prepare_training_data(df):\n",
    "    df = df.dropna(subset=['LapTime', 'Compound', 'Driver'])\n",
    "    df['LapTime'] = pd.to_timedelta(df['LapTime']).dt.total_seconds()\n",
    "\n",
    "    compound_data = {\"SOFT\": [], \"MEDIUM\": [], \"HARD\": []}\n",
    "\n",
    "    for driver in df[\"Driver\"].unique():\n",
    "        driver_df = df[df[\"Driver\"] == driver]\n",
    "\n",
    "        for compound in DEGRADATION_FACTORS.keys():\n",
    "            compound_df = driver_df[driver_df[\"Compound\"] == compound]\n",
    "            if compound_df.empty:\n",
    "                continue\n",
    "\n",
    "            lap_numbers = np.arange(1, len(compound_df) + 1).reshape(-1, 1)\n",
    "            degradation = calculate_degradation(lap_numbers, compound)\n",
    "            lap_times = compound_df['LapTime'].values\n",
    "\n",
    "            fuel_load = np.array([max(INITIAL_FUEL_LOAD - (i * FUEL_BURN_RATE), 0) for i in range(len(lap_times))]).reshape(-1, 1)\n",
    "            track_temp = np.array([INITIAL_TRACK_TEMP - (i // TEMP_DECREASE_LAPS) for i in range(len(lap_times))]).reshape(-1, 1)\n",
    "\n",
    "            compound_data[compound].append((np.hstack((lap_numbers, degradation.reshape(-1, 1), fuel_load, track_temp)), lap_times))\n",
    "\n",
    "    # Merge all drivers' data for each compound\n",
    "    for compound in compound_data:\n",
    "        if compound_data[compound]:\n",
    "            X_all, y_all = zip(*compound_data[compound])\n",
    "            compound_data[compound] = (np.vstack(X_all), np.concatenate(y_all))\n",
    "        else:\n",
    "            compound_data[compound] = (None, None)  # No data for this compound\n",
    "\n",
    "    return compound_data\n",
    "\n",
    "# **Build LSTM Model**\n",
    "def build_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        LSTM(128, return_sequences=True, input_shape=(None, 4)),  # Features: Lap Number, Degradation, Fuel, Temp\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        LSTM(64, return_sequences=False),\n",
    "        tf.keras.layers.Dense(32, activation=LeakyReLU(alpha=0.1)),\n",
    "        tf.keras.layers.Dense(1)  # Output: Lap Time\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='mse',\n",
    "                  metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# **Train Model**\n",
    "def train_model(model, X_train, y_train):\n",
    "    X_train = X_train.reshape((X_train.shape[0], 1, 4))  # Reshape for LSTM\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=1)\n",
    "    return model\n",
    "\n",
    "# **Predict Multiple Laps Sequentially for a Tire Compound**\n",
    "def predict_multiple_laps(model, compound, start_lap, num_laps):\n",
    "    lap_times = []\n",
    "    lap_number = start_lap\n",
    "    last_lap_time = None\n",
    "\n",
    "    for _ in range(num_laps):\n",
    "        fuel_load = max(INITIAL_FUEL_LOAD - (lap_number * FUEL_BURN_RATE), 0)\n",
    "        track_temp = INITIAL_TRACK_TEMP - (lap_number // TEMP_DECREASE_LAPS)\n",
    "\n",
    "        # Calculate degradation for this compound\n",
    "        degradation = calculate_degradation(np.array([lap_number]), compound)[0]\n",
    "\n",
    "        # Create input features\n",
    "        input_features = np.array([[lap_number, degradation, fuel_load, track_temp]]).reshape((1, 1, 4))\n",
    "\n",
    "        # Predict lap time\n",
    "        predicted_time = model.predict(input_features, verbose=0)[0][0]\n",
    "\n",
    "        # If there's a last lap reference, apply penalty if deviation > 5 sec\n",
    "        if last_lap_time is not None and abs(predicted_time - last_lap_time) > 5:\n",
    "            predicted_time = last_lap_time + np.sign(predicted_time - last_lap_time) * 5\n",
    "\n",
    "        lap_times.append(predicted_time)\n",
    "        last_lap_time = predicted_time  # Store last lap time\n",
    "        lap_number += 1\n",
    "\n",
    "    return lap_times\n",
    "\n",
    "# **Convert Lap Time to MM:SS.mmm**\n",
    "def seconds_to_min_sec(lap_time):\n",
    "    return f\"{int(lap_time // 60)}:{lap_time % 60:.3f}\"\n",
    "\n",
    "# **Load Data & Train the Model**\n",
    "df = load_offline_data()\n",
    "if not df.empty:\n",
    "    # **Prepare Data for Each Compound**\n",
    "    compound_data = prepare_training_data(df)\n",
    "\n",
    "    models = {}\n",
    "    for compound, (X_data, y_data) in compound_data.items():\n",
    "        if X_data is not None:\n",
    "            print(f\"\\nTraining {compound} Model...\")\n",
    "            model = build_model()\n",
    "            models[compound] = train_model(model, X_data, y_data)\n",
    "\n",
    "    # **Predict Laps for Each Compound**\n",
    "    print(\"\\nPredicted Lap Times:\")\n",
    "    for compound, model in models.items():\n",
    "        print(f\"\\n{compound} Tire Predictions:\")\n",
    "        predicted_lap_times = predict_multiple_laps(model, compound, start_lap=1, num_laps=NUM_LAPS_TO_PREDICT)\n",
    "        formatted_times = [seconds_to_min_sec(t) for t in predicted_lap_times]\n",
    "\n",
    "        for i, lap_time in enumerate(formatted_times, start=1):\n",
    "            print(f\"Lap {i}: {lap_time}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34c577e0-60de-440a-b9e0-6cd4217391ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 170\u001b[0m\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mae, mse, rmse, r2\n\u001b[0;32m    169\u001b[0m \u001b[38;5;66;03m# **Test Model Performance for Each Compound**\u001b[39;00m\n\u001b[1;32m--> 170\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m compound, model \u001b[38;5;129;01min\u001b[39;00m models\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Evaluating \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcompound\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Tire Model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;66;03m# **Get True Values (y_actual)**\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'models' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LeakyReLU, LSTM\n",
    "from glob import glob\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Constants\n",
    "BATCH_SIZE = 5000\n",
    "MODEL_SAVE_PATH = r\"E:\\fastf1_csv_data\\models\\Australian Grand Prix.h5\"\n",
    "NUM_LAPS_TO_PREDICT = 58  # Number of laps to predict\n",
    "DATA_FOLDER = r\"E:\\fastf1_csv_data\\Data\\Australian Grand Prix\\Race\"\n",
    "\n",
    "# Fuel & Track Temp Inputs\n",
    "INITIAL_FUEL_LOAD = 110  # Full F1 race fuel load (kg)\n",
    "FUEL_BURN_RATE = 1.5  # Estimated fuel loss per lap (kg)\n",
    "INITIAL_TRACK_TEMP = 35  # Track temperature in Celsius\n",
    "TEMP_DECREASE_LAPS = 10  # Decrease track temp by 1°C every 10 laps\n",
    "\n",
    "# **Tire Degradation Parameters**\n",
    "DEGRADATION_FACTORS = {\n",
    "    \"SOFT\": (0.07, 2.0),\n",
    "    \"MEDIUM\": (0.05, 1.5),\n",
    "    \"HARD\": (0.03, 1.2)\n",
    "}\n",
    "\n",
    "# **Load Offline CSV Data**\n",
    "def load_offline_data():\n",
    "    all_files = glob(os.path.join(DATA_FOLDER, '*.csv'))\n",
    "    df_list = [pd.read_csv(file) for file in all_files]\n",
    "    return pd.concat(df_list, ignore_index=True) if df_list else pd.DataFrame()\n",
    "\n",
    "# **Calculate Tire Degradation**\n",
    "def calculate_degradation(lap_numbers, compound):\n",
    "    \"\"\"Degradation is based on different tire compounds.\"\"\"\n",
    "    k1, k2 = DEGRADATION_FACTORS[compound]\n",
    "    return k1 * np.log(k2 * lap_numbers + 1)\n",
    "\n",
    "# **Prepare Training Data (For All Drivers & Compounds)**\n",
    "def prepare_training_data(df):\n",
    "    df = df.dropna(subset=['LapTime', 'Compound', 'Driver'])\n",
    "    df['LapTime'] = pd.to_timedelta(df['LapTime']).dt.total_seconds()\n",
    "\n",
    "    compound_data = {\"SOFT\": [], \"MEDIUM\": [], \"HARD\": []}\n",
    "\n",
    "    for driver in df[\"Driver\"].unique():\n",
    "        driver_df = df[df[\"Driver\"] == driver]\n",
    "\n",
    "        for compound in DEGRADATION_FACTORS.keys():\n",
    "            compound_df = driver_df[driver_df[\"Compound\"] == compound]\n",
    "            if compound_df.empty:\n",
    "                continue\n",
    "\n",
    "            lap_numbers = np.arange(1, len(compound_df) + 1).reshape(-1, 1)\n",
    "            degradation = calculate_degradation(lap_numbers, compound)\n",
    "            lap_times = compound_df['LapTime'].values\n",
    "\n",
    "            fuel_load = np.array([max(INITIAL_FUEL_LOAD - (i * FUEL_BURN_RATE), 0) for i in range(len(lap_times))]).reshape(-1, 1)\n",
    "            track_temp = np.array([INITIAL_TRACK_TEMP - (i // TEMP_DECREASE_LAPS) for i in range(len(lap_times))]).reshape(-1, 1)\n",
    "\n",
    "            compound_data[compound].append((np.hstack((lap_numbers, degradation.reshape(-1, 1), fuel_load, track_temp)), lap_times))\n",
    "\n",
    "    # Merge all drivers' data for each compound\n",
    "    for compound in compound_data:\n",
    "        if compound_data[compound]:\n",
    "            X_all, y_all = zip(*compound_data[compound])\n",
    "            compound_data[compound] = (np.vstack(X_all), np.concatenate(y_all))\n",
    "        else:\n",
    "            compound_data[compound] = (None, None)  # No data for this compound\n",
    "\n",
    "    return compound_data\n",
    "\n",
    "# **Build LSTM Model**\n",
    "def build_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        LSTM(128, return_sequences=True, input_shape=(None, 4)),  # Features: Lap Number, Degradation, Fuel, Temp\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        LSTM(64, return_sequences=False),\n",
    "        tf.keras.layers.Dense(32, activation=LeakyReLU(alpha=0.1)),\n",
    "        tf.keras.layers.Dense(1)  # Output: Lap Time\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='mse',\n",
    "                  metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# **Train Model**\n",
    "def train_model(model, X_train, y_train):\n",
    "    X_train = X_train.reshape((X_train.shape[0], 1, 4))  # Reshape for LSTM\n",
    "    model.fit(X_train, y_train, epochs=500, batch_size=100, verbose=1)\n",
    "    model.save(MODEL_SAVE_PATH)\n",
    "    return model\n",
    "\n",
    "# **Predict Multiple Laps Sequentially for a Tire Compound**\n",
    "def predict_multiple_laps(model, compound, start_lap, num_laps):\n",
    "    lap_times = []\n",
    "    lap_number = start_lap\n",
    "    last_lap_time = None\n",
    "\n",
    "    for _ in range(num_laps):\n",
    "        fuel_load = max(INITIAL_FUEL_LOAD - (lap_number * FUEL_BURN_RATE), 0)\n",
    "        track_temp = INITIAL_TRACK_TEMP - (lap_number // TEMP_DECREASE_LAPS)\n",
    "\n",
    "        # Calculate degradation for this compound\n",
    "        degradation = calculate_degradation(np.array([lap_number]), compound)[0]\n",
    "\n",
    "        # Create input features\n",
    "        input_features = np.array([[lap_number, degradation, fuel_load, track_temp]]).reshape((1, 1, 4))\n",
    "\n",
    "        # Predict lap time\n",
    "        predicted_time = model.predict(input_features, verbose=0)[0][0]\n",
    "\n",
    "        # If there's a last lap reference, apply penalty if deviation > 5 sec\n",
    "        if last_lap_time is not None and abs(predicted_time - last_lap_time) > 5:\n",
    "            predicted_time = last_lap_time + np.sign(predicted_time - last_lap_time) * 5\n",
    "\n",
    "        lap_times.append(predicted_time)\n",
    "        last_lap_time = predicted_time  # Store last lap time\n",
    "        lap_number += 1\n",
    "\n",
    "    return lap_times\n",
    "\n",
    "# **Convert Lap Time to MM:SS.mmm**\n",
    "def seconds_to_min_sec(lap_time):\n",
    "    return f\"{int(lap_time // 60)}:{lap_time % 60:.3f}\"\n",
    "\n",
    "# **Load Data & Train the Model**\n",
    "df = load_offline_data()\n",
    "if not df.empty:\n",
    "    # **Prepare Data for Each Compound**\n",
    "    compound_data = prepare_training_data(df)\n",
    "\n",
    "    models = {}\n",
    "    for compound, (X_data, y_data) in compound_data.items():\n",
    "        if X_data is not None:\n",
    "            print(f\"\\nTraining {compound} Model...\")\n",
    "            model = build_model()\n",
    "            models[compound] = train_model(model, X_data, y_data)\n",
    "\n",
    "    # **Predict Laps for Each Compound**\n",
    "    print(\"\\nPredicted Lap Times:\")\n",
    "    for compound, model in models.items():\n",
    "        print(f\"\\n{compound} Tire Predictions:\")\n",
    "        predicted_lap_times = predict_multiple_laps(model, compound, start_lap=1, num_laps=NUM_LAPS_TO_PREDICT)\n",
    "        formatted_times = [seconds_to_min_sec(t) for t in predicted_lap_times]\n",
    "\n",
    "        for i, lap_time in enumerate(formatted_times, start=1):\n",
    "            print(f\"Lap {i}: {lap_time}\")\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# **Function to Calculate Model Metrics**\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    \"\"\"Calculates accuracy metrics for the model.\"\"\"\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    print(f\"\\n Model Performance Metrics:\")\n",
    "    print(f\" MAE: {mae:.3f} seconds\")\n",
    "    print(f\" MSE: {mse:.3f}\")\n",
    "    print(f\" RMSE: {rmse:.3f} seconds\")\n",
    "    print(f\" R² Score: {r2:.3f}\")\n",
    "\n",
    "    return mae, mse, rmse, r2\n",
    "\n",
    "# **Test Model Performance for Each Compound**\n",
    "for compound, model in models.items():\n",
    "    print(f\"\\n Evaluating {compound} Tire Model...\")\n",
    "    \n",
    "    # **Get True Values (y_actual)**\n",
    "    X_test, y_actual = compound_data[compound]\n",
    "    X_test = X_test.reshape((X_test.shape[0], 1, 4))  # Reshape for LSTM\n",
    "\n",
    "    # **Get Model Predictions (y_predicted)**\n",
    "    y_predicted = model.predict(X_test, verbose=0).flatten()\n",
    "\n",
    "    # **Evaluate the Model**\n",
    "    evaluate_model(y_actual, y_predicted)\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# **Function to Convert Lap Times into Categories**\n",
    "def classify_lap_times(y_actual, y_pred):\n",
    "    \"\"\"Classifies lap times as 'Fast' (1) or 'Slow' (0) based on median time.\"\"\"\n",
    "    threshold = np.median(y_actual)  # Use median lap time as cutoff\n",
    "    y_actual_class = (y_actual <= threshold).astype(int)\n",
    "    y_pred_class = (y_pred <= threshold).astype(int)\n",
    "    return y_actual_class, y_pred_class\n",
    "\n",
    "# **Function to Calculate Classification Metrics**\n",
    "def evaluate_classification(y_actual, y_pred):\n",
    "    y_actual_class, y_pred_class = classify_lap_times(y_actual, y_pred)\n",
    "    \n",
    "    precision = precision_score(y_actual_class, y_pred_class)\n",
    "    recall = recall_score(y_actual_class, y_pred_class)\n",
    "    f1 = f1_score(y_actual_class, y_pred_class)\n",
    "\n",
    "    print(f\"\\n Classification Performance:\")\n",
    "    print(f\" Precision: {precision:.3f}\")\n",
    "    print(f\" Recall: {recall:.3f}\")\n",
    "    print(f\" F1 Score: {f1:.3f}\")\n",
    "\n",
    "    return precision, recall, f1\n",
    "\n",
    "# **Run Classification Evaluation**\n",
    "for compound, model in models.items():\n",
    "    print(f\"\\n Evaluating {compound} Tire Model (Classification)...\")\n",
    "\n",
    "    # **Get True & Predicted Values**\n",
    "    X_test, y_actual = compound_data[compound]\n",
    "    X_test = X_test.reshape((X_test.shape[0], 1, 4))\n",
    "    y_predicted = model.predict(X_test, verbose=0).flatten()\n",
    "\n",
    "    # **Evaluate Classification Performance**\n",
    "    evaluate_classification(y_actual, y_predicted)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c9a1e07-89f6-4849-8848-869b25813dea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb8f0c4-37d2-49ba-a302-e8c071fc14fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "\n",
    "# **Define the saved model path**\n",
    "MODEL_SAVE_PATH = \"E:/fastf1_csv_data/models/2024_Austrian Grand Prix_Race.h5\"\n",
    "\n",
    "# **Load model with custom objects**\n",
    "model = load_model(MODEL_SAVE_PATH, custom_objects={\"LeakyReLU\": LeakyReLU, \"mse\":MeanSquaredError()})\n",
    "print(\"✅ Model loaded successfully!\")\n",
    "\n",
    "# **Constants (Same as during training)**\n",
    "INITIAL_FUEL_LOAD = 110  # kg\n",
    "FUEL_BURN_RATE = 1.5  # kg per lap\n",
    "INITIAL_TRACK_TEMP = 35  # Celsius\n",
    "TEMP_DECREASE_LAPS = 10  # Temp decreases every 10 laps\n",
    "LAPS = 58\n",
    "\n",
    "# **Function to Calculate Tire Degradation**\n",
    "def calculate_degradation(lap_numbers, compound):\n",
    "    \"\"\"Degradation is based on different tire compounds.\"\"\"\n",
    "    DEGRADATION_FACTORS = {\n",
    "        \"SOFT\": (0.07, 2.0),\n",
    "        \"MEDIUM\": (0.05, 1.5),\n",
    "        \"HARD\": (0.03, 1.2)\n",
    "    }\n",
    "    k1, k2 = DEGRADATION_FACTORS[compound]\n",
    "    return k1 * np.log(k2 * lap_numbers + 1)\n",
    "\n",
    "# **Convert Lap Time to MM:SS.mmm**\n",
    "def seconds_to_min_sec(lap_time):\n",
    "    \"\"\"Convert seconds to MM:SS.mmm format.\"\"\"\n",
    "    return f\"{int(lap_time // 60)}:{lap_time % 60:.3f}\"\n",
    "\n",
    "# **Function to Predict a Single Lap Time**\n",
    "def predict_lap_time(model, lap_number, compound):\n",
    "    \"\"\"Predicts lap time for a given lap and tire compound.\"\"\"\n",
    "    degradation = calculate_degradation(np.array([lap_number]), compound)[0]\n",
    "    fuel_load = max(INITIAL_FUEL_LOAD - (lap_number * FUEL_BURN_RATE), 0)\n",
    "    track_temp = INITIAL_TRACK_TEMP - (lap_number // TEMP_DECREASE_LAPS)\n",
    "\n",
    "    input_features = np.array([[lap_number, degradation, fuel_load, track_temp]]).reshape((1, 1, 4))\n",
    "    predicted_time = model.predict(input_features, verbose=0)[0][0]\n",
    "\n",
    "    return predicted_time\n",
    "\n",
    "# **Predict a Single Lap Time (Example: Lap 58 using HARD tires)**\n",
    "predicted_time = predict_lap_time(model, lap_number=58, compound=\"HARD\")\n",
    "formatted_time = seconds_to_min_sec(predicted_time)\n",
    "print(f\"🏎️ Predicted Lap Time for Lap 58 (HARD tires): {formatted_time}\")\n",
    "\n",
    "# **Function to Predict Multiple Laps**\n",
    "def predict_multiple_laps(model, compound, start_lap=1, num_laps=LAPS):\n",
    "    \"\"\"Predicts lap times for multiple laps sequentially.\"\"\"\n",
    "    lap_times = []\n",
    "    for lap_number in range(start_lap, start_lap + num_laps):\n",
    "        predicted_time = predict_lap_time(model, lap_number, compound)\n",
    "        lap_times.append(predicted_time)\n",
    "\n",
    "    return lap_times\n",
    "\n",
    "# **Predict the First 20 Laps for HARD Tires**\n",
    "predicted_laps = predict_multiple_laps(model, compound=\"MEDIUM\", start_lap=1, num_laps=LAPS)\n",
    "\n",
    "# **Print Formatted Results**\n",
    "print(\"\\n🏎️ Predicted Lap Times for HARD Tires:\")\n",
    "for i, time in enumerate(predicted_laps, start=1):\n",
    "    print(f\"Lap {i}: {seconds_to_min_sec(time)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30949d65-ea3f-4ccd-a1fa-0fb50a7a6da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model_path = \"E:/fastf1_csv_data/models/2024_Bahrain Grand Prix_Race.h5\"\n",
    "model = load_model(model_path, compile=False)\n",
    "\n",
    "print(\"Model Input Shape:\", model.input_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35d1d7d3-e569-4d63-8166-3b8c5834db6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model loaded successfully!\n",
      "\n",
      "🏎️ Predicted Lap Times for HARD Tires:\n",
      "Lap 1: 1:33.987\n",
      "Lap 2: 1:35.704\n",
      "Lap 3: 1:35.296\n",
      "Lap 4: 1:34.697\n",
      "Lap 5: 1:34.530\n",
      "Lap 6: 1:34.712\n",
      "Lap 7: 1:35.154\n",
      "Lap 8: 1:35.583\n",
      "Lap 9: 1:35.894\n",
      "Lap 10: 1:35.377\n",
      "Lap 11: 1:35.733\n",
      "Lap 12: 1:36.156\n",
      "Lap 13: 1:36.660\n",
      "Lap 14: 1:37.519\n",
      "Lap 15: 1:38.550\n",
      "Lap 16: 1:39.187\n",
      "Lap 17: 1:39.842\n",
      "Lap 18: 1:41.897\n",
      "Lap 19: 1:43.934\n",
      "Lap 20: 1:42.914\n",
      "Lap 21: 1:41.404\n",
      "Lap 22: 1:40.003\n",
      "Lap 23: 1:39.189\n",
      "Lap 24: 1:38.813\n",
      "Lap 25: 1:38.817\n",
      "Lap 26: 1:39.086\n",
      "Lap 27: 1:39.462\n",
      "Lap 28: 1:39.820\n",
      "Lap 29: 1:40.110\n",
      "Lap 30: 1:39.708\n",
      "Lap 31: 1:39.970\n",
      "Lap 32: 1:40.189\n",
      "Lap 33: 1:40.397\n",
      "Lap 34: 1:40.586\n",
      "Lap 35: 1:40.735\n",
      "Lap 36: 1:40.830\n",
      "Lap 37: 1:40.876\n",
      "Lap 38: 1:40.891\n",
      "Lap 39: 1:40.893\n",
      "Lap 40: 1:40.403\n",
      "Lap 41: 1:40.439\n",
      "Lap 42: 1:40.493\n",
      "Lap 43: 1:40.568\n",
      "Lap 44: 1:40.660\n",
      "Lap 45: 1:40.764\n",
      "Lap 46: 1:40.872\n",
      "Lap 47: 1:40.970\n",
      "Lap 48: 1:41.041\n",
      "Lap 49: 1:41.057\n",
      "Lap 50: 1:40.573\n",
      "Lap 51: 1:40.344\n",
      "Lap 52: 1:39.907\n",
      "Lap 53: 1:39.288\n",
      "Lap 54: 1:38.721\n",
      "Lap 55: 1:38.592\n",
      "Lap 56: 1:38.946\n",
      "Lap 57: 1:39.331\n",
      "Lap 58: 1:39.570\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "\n",
    "\n",
    "MODEL_SAVE_PATH = \"E:/fastf1_csv_data/models/2024_Bahrain Grand Prix_Race.h5\"\n",
    "\n",
    "# **Load model with custom objects**\n",
    "model = load_model(MODEL_SAVE_PATH, custom_objects={\"LeakyReLU\": LeakyReLU, \"mse\":MeanSquaredError()})\n",
    "print(\"✅ Model loaded successfully!\")\n",
    "\n",
    "# **Constants (Same as during training)**\n",
    "INITIAL_FUEL_LOAD = 110  # kg\n",
    "FUEL_BURN_RATE = 1.5  # kg per lap\n",
    "INITIAL_TRACK_TEMP = 35  # Celsius\n",
    "TEMP_DECREASE_LAPS = 10  # Temp decreases every 10 laps\n",
    "LAPS = 58\n",
    "\n",
    "def predict_lap_time(model, lap_number, compound):\n",
    "    \"\"\"Predicts lap time for a given lap and tire compound.\"\"\"\n",
    "    degradation = calculate_degradation(np.array([lap_number]), compound)[0]\n",
    "    fuel_load = max(INITIAL_FUEL_LOAD - (lap_number * FUEL_BURN_RATE), 0)\n",
    "    track_temp = INITIAL_TRACK_TEMP - (lap_number // TEMP_DECREASE_LAPS)\n",
    "\n",
    "    input_features = np.array([[lap_number, degradation, fuel_load, track_temp]]).reshape((1, 1, 4))\n",
    "    predicted_time = model.predict(input_features, verbose=0)[0][0]\n",
    "\n",
    "    return predicted_time\n",
    "def seconds_to_min_sec(lap_time):\n",
    "    \"\"\"Convert seconds to MM:SS.mmm format.\"\"\"\n",
    "    return f\"{int(lap_time // 60)}:{lap_time % 60:.3f}\"\n",
    "    \n",
    "def predict_multiple_laps(model, compound, start_lap=1, num_laps=LAPS):\n",
    "    \"\"\"Predicts lap times for multiple laps sequentially.\"\"\"\n",
    "    lap_times = []\n",
    "    for lap_number in range(start_lap, start_lap + num_laps):\n",
    "        predicted_time = predict_lap_time(model, lap_number, compound)\n",
    "        lap_times.append(predicted_time)\n",
    "\n",
    "    return lap_times\n",
    "\n",
    "predicted_laps = predict_multiple_laps(model, compound=\"HARD\", start_lap=1, num_laps=LAPS)\n",
    "print(\"\\n🏎️ Predicted Lap Times for HARD Tires:\")\n",
    "for i, time in enumerate(predicted_laps, start=1):\n",
    "    print(f\"Lap {i}: {seconds_to_min_sec(time)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56ecdda6-ffd1-4680-af11-0f1b9e029c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM, Dense, LeakyReLU, BatchNormalization\n",
    "from glob import glob\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# **Set Random Seeds for Stability**\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# **Constants**\n",
    "EVENT_NAME = \"Azerbaijan Grand Prix\"\n",
    "SESSION_NAME = \"Race\"\n",
    "YEAR = \"2024\"\n",
    "MODEL_SAVE_PATH = f\"E:/fastf1_csv_data/models/{YEAR}_{EVENT_NAME}_{SESSION_NAME}.h5\"\n",
    "\n",
    "BATCH_SIZE = 5000\n",
    "NUM_LAPS_TO_PREDICT = 57\n",
    "DATA_FOLDER = r\"E:\\fastf1_csv_data\\Data\\Azerbaijan Grand Prix\"\n",
    "\n",
    "# **Fuel & Track Temp Inputs**\n",
    "INITIAL_FUEL_LOAD = 110  # Max fuel (kg)\n",
    "FUEL_BURN_RATE = 1.5  # kg per lap\n",
    "INITIAL_TRACK_TEMP = 35  # Track temperature in Celsius\n",
    "TEMP_DECREASE_LAPS = 10  # Decrease track temp by 1°C every 10 laps\n",
    "\n",
    "# **Tire Wear Limits**\n",
    "TIRE_LIFESPAN = {\"SOFT\": 25, \"MEDIUM\": 35, \"HARD\": 45}\n",
    "\n",
    "# **Tire Degradation Parameters**\n",
    "DEGRADATION_FACTORS = {\n",
    "    \"SOFT\": (0.07, 2.0),\n",
    "    \"MEDIUM\": (0.05, 1.5),\n",
    "    \"HARD\": (0.03, 1.2)\n",
    "}\n",
    "\n",
    "# **Load CSV Data**\n",
    "def load_offline_data():\n",
    "    all_files = glob(os.path.join(DATA_FOLDER, '*.csv'))\n",
    "    df_list = [pd.read_csv(file) for file in all_files]\n",
    "    return pd.concat(df_list, ignore_index=True) if df_list else pd.DataFrame()\n",
    "\n",
    "# **Calculate Tire Degradation**\n",
    "def calculate_degradation(lap_numbers, compound):\n",
    "    k1, k2 = DEGRADATION_FACTORS[compound]\n",
    "    return k1 * np.log(k2 * lap_numbers + 1)\n",
    "\n",
    "# **Prepare Training Data**\n",
    "def prepare_training_data(df):\n",
    "    df = df.dropna(subset=['LapTime', 'Compound', 'Driver'])\n",
    "    df['LapTime'] = pd.to_timedelta(df['LapTime']).dt.total_seconds()\n",
    "\n",
    "    compound_data = {\"SOFT\": [], \"MEDIUM\": [], \"HARD\": []}\n",
    "\n",
    "    for driver in df[\"Driver\"].unique():\n",
    "        driver_df = df[df[\"Driver\"] == driver]\n",
    "\n",
    "        for compound in DEGRADATION_FACTORS.keys():\n",
    "            compound_df = driver_df[driver_df[\"Compound\"] == compound]\n",
    "            if compound_df.empty:\n",
    "                continue\n",
    "\n",
    "            lap_numbers = np.arange(1, len(compound_df) + 1).reshape(-1, 1)\n",
    "            degradation = calculate_degradation(lap_numbers, compound)\n",
    "            lap_times = compound_df['LapTime'].values\n",
    "\n",
    "            fuel_load = np.array([max(INITIAL_FUEL_LOAD - (i * FUEL_BURN_RATE), 0) for i in range(len(lap_times))]).reshape(-1, 1)\n",
    "            track_temp = np.array([INITIAL_TRACK_TEMP - (i // TEMP_DECREASE_LAPS) for i in range(len(lap_times))]).reshape(-1, 1)\n",
    "\n",
    "            compound_data[compound].append((np.hstack((lap_numbers, degradation.reshape(-1, 1), fuel_load, track_temp)), lap_times))\n",
    "\n",
    "    for compound in compound_data:\n",
    "        if compound_data[compound]:\n",
    "            X_all, y_all = zip(*compound_data[compound])\n",
    "            compound_data[compound] = (np.vstack(X_all), np.concatenate(y_all))\n",
    "        else:\n",
    "            compound_data[compound] = (None, None)\n",
    "\n",
    "    return compound_data\n",
    "\n",
    "# **Build LSTM Model**\n",
    "def build_model():\n",
    "    model = Sequential([\n",
    "        LSTM(128, return_sequences=True, input_shape=(None, 4)),\n",
    "        BatchNormalization(),\n",
    "        LSTM(64, return_sequences=False),\n",
    "        Dense(32, activation=LeakyReLU(negative_slope=0.1)),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='mse',\n",
    "                  metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# **Train Model & Save It**\n",
    "def train_model(model, X_train, y_train):\n",
    "    X_train = X_train.reshape((X_train.shape[0], 1, 4))\n",
    "    model.fit(X_train, y_train, epochs=300, batch_size=32, verbose=1)\n",
    "    model.save(MODEL_SAVE_PATH)\n",
    "    return model\n",
    "\n",
    "# **Predict Multiple Laps**\n",
    "def predict_multiple_laps(model, compound, start_lap, num_laps):\n",
    "    lap_times = []\n",
    "    lap_number = start_lap\n",
    "    last_lap_time = None\n",
    "\n",
    "    for _ in range(num_laps):\n",
    "        fuel_load = max(INITIAL_FUEL_LOAD - (lap_number * FUEL_BURN_RATE), 0)\n",
    "        track_temp = INITIAL_TRACK_TEMP - (lap_number // TEMP_DECREASE_LAPS)\n",
    "        degradation = calculate_degradation(np.array([lap_number]), compound)[0]\n",
    "\n",
    "        if lap_number > TIRE_LIFESPAN[compound]:\n",
    "            degradation *= 2.5  # Extreme degradation beyond max lifespan\n",
    "            print(f\"⚠️ {compound} tire exceeded lifespan ({TIRE_LIFESPAN[compound]} laps). Expect slower lap times!\")\n",
    "\n",
    "        input_features = np.array([[lap_number, degradation, fuel_load, track_temp]]).reshape((1, 1, 4))\n",
    "        predicted_time = model.predict(input_features, verbose=0)[0][0]\n",
    "\n",
    "        if last_lap_time is not None and abs(predicted_time - last_lap_time) > 5:\n",
    "            predicted_time = last_lap_time + np.sign(predicted_time - last_lap_time) * 5\n",
    "\n",
    "        lap_times.append(predicted_time)\n",
    "        last_lap_time = predicted_time\n",
    "        lap_number += 1\n",
    "\n",
    "    return lap_times\n",
    "\n",
    "# **Convert Lap Time to MM:SS.mmm**\n",
    "def seconds_to_min_sec(lap_time):\n",
    "    return f\"{int(lap_time // 60)}:{lap_time % 60:.3f}\"\n",
    "\n",
    "# **Load Data & Train**\n",
    "df = load_offline_data()\n",
    "if not df.empty:\n",
    "    compound_data = prepare_training_data(df)\n",
    "    models = {}\n",
    "\n",
    "    for compound, (X_data, y_data) in compound_data.items():\n",
    "        if X_data is not None:\n",
    "            print(f\"\\n🚗 Training {compound} Model...\")\n",
    "            model = build_model()\n",
    "            models[compound] = train_model(model, X_data, y_data)\n",
    "\n",
    "    # **Predict Lap Times**\n",
    "    print(\"\\n🏎️ Predicted Lap Times:\")\n",
    "    for compound, model in models.items():\n",
    "        print(f\"\\n🔹 {compound} Tire Predictions:\")\n",
    "        predicted_lap_times = predict_multiple_laps(model, compound, start_lap=1, num_laps=NUM_LAPS_TO_PREDICT)\n",
    "        formatted_times = [seconds_to_min_sec(t) for t in predicted_lap_times]\n",
    "\n",
    "        for i, lap_time in enumerate(formatted_times, start=1):\n",
    "            print(f\"Lap {i}: {lap_time}\")\n",
    "\n",
    "        # **Evaluate Model**\n",
    "        X_test, y_actual = compound_data[compound]\n",
    "        y_predicted = model.predict(X_test.reshape((X_test.shape[0], 1, 4)), verbose=0).flatten()\n",
    "        evaluate_model(y_actual, y_predicted)\n",
    "        evaluate_classification(y_actual, y_predicted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba7fa00-0d0c-4934-979e-06f08242fe04",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade ipykernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7115ce28-34fe-4aab-a48f-7d41e8cc1691",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
